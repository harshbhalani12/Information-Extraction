{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key verb: release, launch\n",
    "# handles conj where \"premiered and released\"\n",
    "# subject for the key verb as movie\n",
    "# temporal of key verb\n",
    "# location of key verb\n",
    "# attachment with \"by\" for owner\n",
    "# predefined set of format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'The IronMan premiered at the Sundance Film Festival on January 21, 2018, and was theatrically released on January 24, 2018 in the United States by Mr. Bhalani.'\n",
    "s2 = 'Ironman was released in the United States on May 2, 2008.'\n",
    "s3 = 'The film was theatrically released in the United States on October 5, 2018, distributed by Warner Bros.'\n",
    "s4 = \"Black Panther premiered in Los Angeles on January 29, 2018, and was released theatrically in the United States on February 16, in 2D, 3D, IMAX and other premium large formats.\"\n",
    "s5 = 'Captain America: The First Avenger premiered in Hollywood on July 19, 2011, and was released in the United States on July 22, 2011.'\n",
    "s6 = 'Mission: Impossible – Fallout had its world premiere in Paris on July 12, 2018 and was released in the United States on July 27, 2018.'\n",
    "s7 = 'First Man had its world premiere at the Venice Film Festival on August 29, 2018, and was theatrically released in the United States on October 12, 2018, by Universal Pictures.'\n",
    "s8 = 'The Godfather was commercially released on March 24, 1972, throughout the rest of the United States.'\n",
    "#location not detected becasue \"the United States\" was attached to \"rest of\" and not verb.\n",
    "s8_1 = 'The Godfather was commercially released on March 24, 1972, throughout the United States.'\n",
    "s9 = 'The Film began releasing in international markets on April 30, and was released in the United States on May 2, 2008.'\n",
    "s10 = 'A sequel, Mission: Impossible – Fallout, was released on July 27, 2018 with McQuarrie returning as writer and director.'\n",
    "s11 = 'The Film premiered at the Sundance Film Festival on January 21, 2018, and was theatrically released in the United States on August 24, 2018, by Screen Gems.'\n",
    "#sometimes person name with release confuses the parse. because some movienames are based on person names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Movie Release ----\n",
      "MovieName: <no-match>\n",
      "Time: May 2, 2008\n",
      "Location: <no-match>\n",
      "Owner: <no-match>\n",
      "Formats: <no-match>\n"
     ]
    }
   ],
   "source": [
    "sent = s9\n",
    "parse(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(statement):\n",
    "    isValidForReleaseTemplate = checkReleaseMovieTemplateEligibility(statement)\n",
    "    result = None\n",
    "    if(isValidForReleaseTemplate):\n",
    "        sTime = extractReleaseTimeSyntactically(statement)\n",
    "        movieName = extractMovieName(statement)\n",
    "        location = extractReleaseLocationSyntactically(statement)\n",
    "        owner = extractOwnerEntitySyntactically(statement)\n",
    "        formats = extractMovieFormat(statement)\n",
    "        result = [movieName, sTime, location, owner, formats]\n",
    "    printResult(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResult(result):\n",
    "    print(\"---- Movie Release ----\")\n",
    "    if result != None:\n",
    "        print(\"MovieName:\",result[0])\n",
    "        print(\"Time:\",result[1])\n",
    "        print(\"Location:\", result[2])\n",
    "        print(\"Owner:\", result[3])\n",
    "        print(\"Formats:\", result[4])\n",
    "    else:\n",
    "        print(\"No Parse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMovieFormat(statement):\n",
    "    validFormats = [\"2D\", \"3D\", \"IMAX\", \"Blu-ray\", \"DVD\"]\n",
    "    formats = []\n",
    "    for validFormat in validFormats:\n",
    "        if validFormat in statement:\n",
    "            formats.append(validFormat)\n",
    "    if len(formats) > 0:\n",
    "        return formats\n",
    "    else:\n",
    "        return \"<no-match>\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMovieName(statement):\n",
    "    targetVerbLemmas = ['release', 'launch']\n",
    "    verbText = getTargetVerbAsAppearedInStatement(statement, targetVerbLemmas)\n",
    "    verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "    movieName = \"<uninitialized>\"\n",
    "    \n",
    "#     handle when release is with premiered.\n",
    "    while verbTextDNode[1] == 'conj':\n",
    "        verbText = verbTextDNode[2]\n",
    "        verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "\n",
    "#     print(verbText)\n",
    "    nounSubject = getNounSubject(statement, verbText)\n",
    "#     print(\"ns:\"+nounSubject)\n",
    "    movieName = getNounChunkThatContainsNoun(statement, nounSubject)\n",
    "\n",
    "    return movieName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNounChunkThatContainsNoun(statement, nounSubject):\n",
    "    doc = nlp(statement)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if nounSubject in chunk.text:\n",
    "            return chunk.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemporalThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and (ent.label_ == \"DATE\" or ent.label_ == \"TIME\") and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    \n",
    "    return \"<no-match>\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGPEThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and ent.label_ == \"GPE\" and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getORGorPersonThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and (ent.label_ == \"ORG\" or ent.label_ == \"PERSON\") and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def calculateStartPositionOfToken(statement, targetToken):\n",
    "    \"\"\"\n",
    "    this should return start position of the token\n",
    "    \"\"\"\n",
    "    matches = [m.start() for m in re.finditer(targetToken.text, statement)]\n",
    "    if(len(matches)==1):\n",
    "        return matches[0]\n",
    "    \n",
    "\n",
    "    huristicPosition = 0\n",
    "    doc = nlp(statement)\n",
    "    \n",
    "    i = 0\n",
    "    for token in doc:\n",
    "        if i < targetToken.i:\n",
    "            huristicPosition = huristicPosition + len(token.text)+1\n",
    "            i = i+1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    distances = []\n",
    "    for match in matches:\n",
    "        distances.append(abs(match-huristicPosition))\n",
    "        \n",
    "    minIndex = distances.index(min(distances))\n",
    "    \n",
    "    return matches[minIndex]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNounSubject(statement, verbText):\n",
    "    doc = nlp(statement)\n",
    "    for token in doc:\n",
    "        if((token.dep_ == \"nsubjpass\" or token.dep_ == \"nsubj\") and token.head.text == verbText):\n",
    "            return token.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetVerbAsAppearedInStatement(statement, targetVerbLemmas):\n",
    "    \"\"\"\n",
    "    this will reutrn exact apperance of verb in statement.\n",
    "    ex: statement = \"Movie was written by James.\", targetVerbLemmas = ['write','script']\n",
    "    this will return \"written\" as it's lemma matches with one of the targetVerbLemmas\n",
    "    \"\"\"\n",
    "    verbTokens = filterVerbTokens(statement)\n",
    "    for token in verbTokens:\n",
    "        if token.lemma_ in targetVerbLemmas:\n",
    "            return token.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractReleaseTimeSyntactically(statement):\n",
    "    doc = nlp(statement)\n",
    "    verbTokens = filterVerbTokens(statement)\n",
    "    \n",
    "    for token in verbTokens:\n",
    "        if isExpectedToken(token):\n",
    "#             print(\"Expected token is:\"+token.text)\n",
    "            #expected children [was, theatrically, in, on, by]\n",
    "            for child in token.children: \n",
    "                #usually release time starts with \"on\"\n",
    "                if child.text == \"on\":\n",
    "                    #usually \"on\"'s child is [August] \n",
    "                    for subChild in child.children:\n",
    "                        temporalEntity = getTemporalThatContainsToken(statement, subChild)\n",
    "                        return temporalEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractReleaseLocationSyntactically(statement):\n",
    "    doc = nlp(statement)\n",
    "    verbTokens = filterVerbTokens(statement)\n",
    "    \n",
    "    for token in verbTokens:\n",
    "        if isExpectedToken(token):\n",
    "#             print(\"Expected token is:\"+token.text)\n",
    "            #expected children [was, theatrically, in, on, by]\n",
    "            for child in token.children: \n",
    "                #usually release location starts with \"in\"\n",
    "                if child.text in [\"in\",\"throughout\"]:\n",
    "                    for subChild in child.children:\n",
    "                        GPEEntity = getGPEThatContainsToken(statement, subChild)\n",
    "                        return GPEEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractOwnerEntitySyntactically(statement):\n",
    "    doc = nlp(statement)\n",
    "    verbTokens = filterVerbTokens(statement)\n",
    "    \n",
    "    for token in verbTokens:\n",
    "        if isExpectedToken(token):\n",
    "#             print(\"Expected token is:\"+token.text)\n",
    "            #expected children [was, theatrically, in, on, by]\n",
    "            for child in token.children: \n",
    "                #usually release location starts with \"in\"\n",
    "                if child.text == \"by\":\n",
    "                    for subChild in child.children:\n",
    "                        ORGEntity = getORGorPersonThatContainsToken(statement, subChild)\n",
    "                        return ORGEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isExpectedToken(token):\n",
    "    return token.lemma_ in [\"release\",\"launch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkReleaseMovieTemplateEligibility(statement):\n",
    "    hasValidVerb = check_verb_match(statement)\n",
    "#     print(\"Has valid verb:\"+str(hasValidVerb))\n",
    "    \n",
    "    hasDateEntity = check_date_entity_match(statement)\n",
    "#     print(\"Has DATE included:\"+str(hasDateEntity))\n",
    "    return hasValidVerb and hasDateEntity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_date_entity_match(statement):\n",
    "    doc = nlp(statement)\n",
    "    result = len(list(filter(lambda entity: entity.label_ == \"DATE\" , doc.ents))) > 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_verb_match(statement):\n",
    "    verbTokens = filterVerbTokens(statement)\n",
    "    targetVerbs = ['release', 'launch']\n",
    "    for token in verbTokens:\n",
    "        if token.lemma_ in targetVerbs:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterVerbTokens(statement):\n",
    "    doc = nlp(statement)\n",
    "    result = list(filter(lambda token: token.pos_ == \"VERB\" and token.lemma_ != \"be\", doc))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRootToken(doc):\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            return token\n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_dist(word1, word2):\n",
    "    token1 = nlp(word1)[0]\n",
    "    token2 = nlp(word2.lemma_)[0]\n",
    "    return token1.similarity(token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependency_tree_nodes(sentence):\n",
    "    nodes = []\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        nodes.append([token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "          [child for child in token.children]])\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
