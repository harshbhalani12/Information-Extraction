{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1 = \"Rotten Tomatoes gave 7/10 ratings to the Mission Impossible based on 273 users reviews.\"\n",
    "s2 = 'The Mission Impossible was given 7/10 ratings by Rotten Tomatoes.'\n",
    "s3 = 'The Mission Impossible was rated 7/10 ratings by Rotten Tomatoes.'\n",
    "s4 = 'The IMDB gave 7.9/10 ratings to the Mission Impossible based on 305 reviews of users.'\n",
    "s5 = 'Rotten Tomatoes gave 7/10 ratings to the Mission Impossible.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching with wriiten template: for The IMDB gave 7.9/10 ratings to the Mission Impossible based on 305 reviews of users.\n",
      "Has valid verb:True\n",
      "--------- Extracted Information -----------\n",
      "Movie name : the Mission Impossible\n",
      "Ratings :  7.9/10\n",
      "Rated by :  The IMDB\n",
      "Total reviews :  305\n"
     ]
    }
   ],
   "source": [
    "sentence = s4\n",
    "parse(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(statement1):\n",
    "    isValidForRatingTemplate = checkRatingTemplateEligibility(statement1)\n",
    "    if(isValidForRatingTemplate):\n",
    "\n",
    "        print(\"--------- Extracted Information -----------\")\n",
    "        \n",
    "        movieName = extractMovieName(statement1)\n",
    "        print(\"Movie name : \" + str(movieName))\n",
    "\n",
    "        ratings = extractRatings(statement1)\n",
    "        print(\"Ratings : \" , ratings)\n",
    "\n",
    "        ratingsbyWhom = extractGiverName(statement1)\n",
    "        print(\"Rated by : \" , ratingsbyWhom)\n",
    "\n",
    "        totalReviews = extractTotalReviews(statement1)\n",
    "        print(\"Total reviews : \" , totalReviews)\n",
    "    else:\n",
    "        print(\" NO - PARSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching with wriiten template: for Rotten Tomatoes gave 7/10 ratings to the Mission Impossible based on 273 users reviews.\n",
      "Has valid verb:True\n",
      "extracted movie name is:the Mission Impossible\n",
      "extracted Ratings :  7/10\n",
      "extracted rated by entity is: Rotten Tomatoes\n",
      "extracted total reviews are: 273\n"
     ]
    }
   ],
   "source": [
    "# statement1 = 'The Mission Impossible was given 7/10 ratings by Rotten Tomatoes.'\n",
    "# statement1 = 'The Mission Impossible was rated 7/10 ratings by Rotten Tomatoes.'\n",
    "statement1 = 'Rotten Tomatoes gave 7/10 ratings to the Mission Impossible based on 273 users reviews.'\n",
    "# statement1 = 'Rotten Tomatoes gave 7/10 ratings to the Mission Impossible.'\n",
    "\n",
    "\n",
    "isValidForRatingTemplate = checkRatingTemplateEligibility(statement1)\n",
    "if(isValidForRatingTemplate):\n",
    "    \n",
    "    movieName = extractMovieName(statement1)\n",
    "    print(\"extracted movie name is:\" + str(movieName))\n",
    "    \n",
    "    ratings = extractRatings(statement1)\n",
    "    print(\"extracted Ratings : \" , ratings)\n",
    "    \n",
    "    ratingsbyWhom = extractGiverName(statement1)\n",
    "    print(\"extracted rated by entity is:\" , ratingsbyWhom)\n",
    "    \n",
    "    totalReviews = extractTotalReviews(statement1)\n",
    "    print(\"extracted total reviews are:\" , totalReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractMovieName(statement):\n",
    "    targetVerbLemmas = ['rat' , 'give'] # rat is a lemma for verb rate\n",
    "    verbText = getTargetVerbAsAppearedInStatement(statement, targetVerbLemmas)\n",
    "    verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "    movieName = \"<uninitialized>\"\n",
    "    \n",
    "#     handle when release is with premiered.\n",
    "    '''\n",
    "    while verbTextDNode[1] == 'conj':\n",
    "        verbText = verbTextDNode[2]\n",
    "        print(\"verbTextChanged to : \"+verbText)\n",
    "        verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "    '''\n",
    "\n",
    "    #print(\"vt:\"+verbText)\n",
    "\n",
    "    movieName = getMovie(statement,verbText)\n",
    "    \n",
    "    return movieName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractGiverName(statement):\n",
    "    targetVerbLemmas = ['rat' , 'give']\n",
    "    \n",
    "    verbText = getTargetVerbAsAppearedInStatement(statement, targetVerbLemmas)\n",
    "    verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "    writerName = \"<uninitialized>\"\n",
    "    \n",
    "    '''\n",
    "#     handle when release is with premiered.\n",
    "    while verbTextDNode[1] == 'conj':\n",
    "        verbText = verbTextDNode[2]\n",
    "        print(\"verbTextChanged to\"+verbText)\n",
    "        verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "    '''\n",
    "\n",
    "    #print(\"vt:\"+verbText)\n",
    "\n",
    "    writerName = getWriter(statement,verbText)\n",
    "    \n",
    "    return writerName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractRatings(statement):\n",
    "    targetVerbLemmas = ['rat' , 'give']\n",
    "    verbText = getTargetVerbAsAppearedInStatement(statement, targetVerbLemmas)\n",
    "    verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "    ratings = \"<uninitialized>\"\n",
    "    \n",
    "    #print(\"vt:\"+verbText)\n",
    "\n",
    "    ratings = getRatings(statement,verbText)\n",
    "    \n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractTotalReviews(statement):\n",
    "    targetVerbLemmas = ['rat' , 'give']\n",
    "    verbText = getTargetVerbAsAppearedInStatement(statement, targetVerbLemmas)\n",
    "    verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "    totalReviews = \"<uninitialized>\"\n",
    "    \n",
    "    totalReviews = getTotalReviews(statement)\n",
    "    \n",
    "    return totalReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTargetVerbAsAppearedInStatement(statement, targetVerbLemmas):\n",
    "    \"\"\"\n",
    "    this will reutrn exact apperance of verb in statement.\n",
    "    ex: statement = \"Movie was written by James.\", targetVerbLemmas = ['write','script']\n",
    "    this will return \"written\" as it's lemma matches with one of the targetVerbLemmas\n",
    "    \"\"\"\n",
    "    verbTokens = filterVerbTokens(statement)\n",
    "    for token in verbTokens:\n",
    "        if token.lemma_ in targetVerbLemmas:\n",
    "            return token.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNounSubject(statement, verbText):\n",
    "    doc = nlp(statement)\n",
    "    for token in doc:\n",
    "        print(token.text, token.dep_, token.head.text)\n",
    "        if((token.dep_ == \"nsubjpass\" or token.dep_ == \"nsubj\") and token.head.text == verbText):\n",
    "            return token.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMovie(statement, verbText):\n",
    "    doc = nlp(statement)\n",
    "    theme = \"<uninitialized>\" #movie\n",
    "    \n",
    "    for token in doc:\n",
    "        #print(token.text, token.dep_, token.head.text)        \n",
    "        if (token.dep_ == \"nsubjpass\" and token.head.text == verbText):\n",
    "            #print(\"token nsubjpass : \" + token.text)\n",
    "            theme = getNounChunkThatContainsNoun(statement, token)\n",
    "            return theme\n",
    "        elif (token.text == \"to\" and token.head.text == verbText):\n",
    "            #print(\"to:\")\n",
    "            childToken = [child for child in token.children][0]\n",
    "            #print(\"child:\",childToken)\n",
    "            theme = getNounChunkThatContainsNoun(statement, childToken)\n",
    "            return theme\n",
    "        #elif (token.dep_ == \"dobj\" and token.head.text == verbText):\n",
    "            #print(\"token dobj\")\n",
    "            #theme = getNounChunkThatContainsNoun(statement, token)\n",
    "            #return theme\n",
    "        elif ((token.dep_ == \"conj\" and token.head.text == verbText) or (token.dep_ == \"conj\" and token.text == verbText)):\n",
    "            #print(\"token conj : \" + token.text)\n",
    "            if (token.head.dep_ == \"ROOT\"):\n",
    "                #print(\"token.head: \" + token.head.text)\n",
    "                token1 = token.head\n",
    "                return getMovie(statement, token1.text)\n",
    "                '''\n",
    "                if (token.dep_ == \"nsubjpass\" and token.head.text == token1.text):\n",
    "                    theme = getNounChunkThatContainsNoun(statement, token)\n",
    "                    return theme\n",
    "                '''\n",
    "    \n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWriter(statement, verbText):\n",
    "    doc = nlp(statement)\n",
    "    agent = \"<uninitialized>\" #writer\n",
    "    '''\n",
    "    for token in doc:\n",
    "        #print(token.text, token.dep_, token.head.text)        \n",
    "        if (token.dep_ == \"agent\" and token.head.text == verbText):\n",
    "            token = [child for child in token.children][0]\n",
    "            agent = getNounChunkThatContainsNoun(statement, token)\n",
    "            return agent\n",
    "        elif (token.dep_ == \"nsubj\" and token.head.text == verbText):\n",
    "            agent = getNounChunkThatContainsNoun(statement, token)\n",
    "            return agent\n",
    "    '''\n",
    "    \n",
    "    for token in doc:\n",
    "        #print(\"token:\",token)\n",
    "        '''\n",
    "        if (token.dep_ == \"agent\" and token.head.text == verbText):\n",
    "            token = [child for child in token.children][0]\n",
    "            agent = getNounChunkThatContainsNoun(statement, token)\n",
    "            print(\"Agent (agent) : \" + agent)\n",
    "            return agent\n",
    "        '''\n",
    "        if (token.dep_ == \"nsubj\" and token.head.text == verbText):\n",
    "            agent = getNounChunkThatContainsNoun(statement, token)\n",
    "            #print(\"Agent (nsubj) : \" + agent)\n",
    "            return agent\n",
    "        \n",
    "        elif((token.dep_ == \"conj\" and token.head.text == verbText) or (token.dep_ == \"conj\" and token.text == verbText)):\n",
    "            agent = extractOwnerEntitySyntactically(statement)\n",
    "            return agent\n",
    "        \n",
    "        elif(token.head.text == verbText or token.text == verbText):\n",
    "            #print(token.head.text)\n",
    "            agent = extractOwnerEntitySyntactically(statement)\n",
    "            return agent\n",
    "        \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractOwnerEntitySyntactically(statement):\n",
    "    doc = nlp(statement)\n",
    "    verbTokens = filterVerbTokens(statement)\n",
    "    ORGEntity = []\n",
    "    \n",
    "    for token in verbTokens:\n",
    "        if isExpectedVerbToken(token):\n",
    "            #print(\"Expected token is:\"+token.text)\n",
    "            #expected children [was, theatrically, in, on, by]\n",
    "            byToken = None\n",
    "            for child in token.children: \n",
    "                #usually release location starts with \"in\"\n",
    "                if child.text == \"by\":\n",
    "                    byToken = child\n",
    "             \n",
    "            if byToken == None:\n",
    "                #means no direct by available so lets look at some conj child\n",
    "                for child in token.children: \n",
    "                    #usually release location starts with \"in\"\n",
    "                    if child.dep_ == \"conj\":\n",
    "                        for grandChild in child.children:\n",
    "                            if grandChild.text == \"by\":\n",
    "                                byToken = grandChild\n",
    "                    else:\n",
    "                        for grandChild in child.children:\n",
    "                            if grandChild.text == \"by\":\n",
    "                                byToken = grandChild\n",
    "            \n",
    "            #print(\"byToken:\" , byToken)\n",
    "            \n",
    "            if byToken != None:\n",
    "                for subChild in byToken.children:\n",
    "                    ORGEntity.append(getORGorPersonThatContainsToken(statement, subChild))\n",
    "                    #print(\"subchild : \" + subChild.text)\n",
    "                    if (subChild.dep_ == \"pobj\" and subChild.head.text == \"by\"):\n",
    "                        grandChildren = subChild.children\n",
    "                        childEntity = getORGEntityForGrandChild1(statement, grandChildren, ORGEntity)\n",
    "                        #print(\"child entity:    \" , str(childEntity))\n",
    "                        return list(set(childEntity))\n",
    "                        #ORGEntity.clear()\n",
    "                        #for item in childEntity:\n",
    "                            #ORGEntity.append(item)\n",
    "                    return ORGEntity\n",
    "        #else: \n",
    "            #print(isExpectedVerbToken(token))\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getORGEntityForGrandChild1(statement, children, ORGEntity):\n",
    "    '''\n",
    "    New definition\n",
    "    '''\n",
    "    doc = nlp(statement)\n",
    "    \n",
    "    for child in children:\n",
    "        sizeChild = sum(1 for item in child.children)\n",
    "        #print(child, sizeChild)\n",
    "        if sizeChild > 0:\n",
    "            ORGEntity.append(getORGorPersonThatContainsToken(statement, child))\n",
    "            #print(ORGEntity)\n",
    "            #ORGEntity.append(getORGEntityForGrandChild1(statement, child.children, ORGEntity))\n",
    "            getORGEntityForGrandChild1(statement, child.children, ORGEntity)\n",
    "        if sizeChild == 0:\n",
    "            if (getORGorPersonThatContainsToken(statement, child) != \"<no-match>\"):\n",
    "                ORGEntity.append(getORGorPersonThatContainsToken(statement, child))\n",
    "    \n",
    "    return ORGEntity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRatings(statement, verbText):\n",
    "    doc = nlp(statement)\n",
    "    \n",
    "    ratings = \"<uninitialized>\"\n",
    "    \n",
    "    if (check_word_pattern(statement, \" ratings \")):\n",
    "        for token in doc:\n",
    "            if (token.head.text == \"ratings\"):\n",
    "                ratings = getORGorPersonThatContainsToken(statement, token)\n",
    "                return ratings\n",
    "        \n",
    "    else:\n",
    "        for token in doc:\n",
    "            if (token.head.text == verbText and (token.dep_ == \"dobj\" or token.dep_ == \"oprd\")):\n",
    "                ratings = getORGorPersonThatContainsToken(statement, token)\n",
    "                return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTotalReviews(statement):\n",
    "    doc = nlp(statement)\n",
    "    \n",
    "    totalReviews = \"<uninititalized>\"\n",
    "    \n",
    "    if (check_word_pattern(statement, \" based on \")):\n",
    "        for token in doc:\n",
    "            if (token.text == \"on\" and token.head.text == \"based\"):\n",
    "                child = [child1 for child1 in token.children][0] # reviews\n",
    "                for token1 in doc:\n",
    "                    if (token1.head.text == child.text):\n",
    "                        return token1.text\n",
    "                    \n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isExpectedVerbToken(token):\n",
    "    return (token.lemma_ in [\"give\"] or token.lemma_ in [\"rat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getORGorPersonThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def calculateStartPositionOfToken(statement, targetToken):\n",
    "    \"\"\"\n",
    "    this should return start position of the token\n",
    "    \"\"\"\n",
    "    matches = [m.start() for m in re.finditer(targetToken.text, statement)]\n",
    "    if(len(matches)==1):\n",
    "        return matches[0]\n",
    "    \n",
    "\n",
    "    huristicPosition = 0\n",
    "    doc = nlp(statement)\n",
    "    \n",
    "    i = 0\n",
    "    for token in doc:\n",
    "        if i < targetToken.i:\n",
    "            huristicPosition = huristicPosition + len(token.text)+1\n",
    "            i = i+1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    distances = []\n",
    "    for match in matches:\n",
    "        distances.append(abs(match-huristicPosition))\n",
    "        \n",
    "    minIndex = distances.index(min(distances))\n",
    "    \n",
    "    return matches[minIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNounChunkThatContainsNoun(statement, nounSubject):\n",
    "    doc = nlp(statement)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if nounSubject.text in chunk.text:\n",
    "            return chunk.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkRatingTemplateEligibility(statement):\n",
    "    print(\"Matching with wriiten template: for \" + statement)\n",
    "    hasValidVerb = check_verb_match(statement)\n",
    "    print(\"Has valid verb:\" + str(hasValidVerb))\n",
    "    \n",
    "    return hasValidVerb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_verb_match(statement):\n",
    "    verbTokens = filterVerbTokens(statement)\n",
    "    \n",
    "    targetVerbs = ['rat', 'give']\n",
    "    for token in verbTokens:\n",
    "        if token.lemma_ in targetVerbs:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_word_pattern(statement, pattern1):\n",
    "    return ((pattern1 in statement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_verb_match('The Mission Impossible was rated 7/10 by Rotten Tomatoes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterVerbTokens(statement):\n",
    "    doc = nlp(statement)\n",
    "    result = list(filter(lambda token: token.pos_ == \"VERB\" and token.lemma_ != \"be\", doc))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[rated]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterVerbTokens('The Mission Impossible was rated 7/10 by Rotten Tomatoes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dependency_tree_nodes(sentence):\n",
    "    nodes = []\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        nodes.append([token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "          [child for child in token.children]])\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'det', 'Impossible', 'PROPN', []],\n",
       " ['Mission', 'compound', 'Impossible', 'PROPN', []],\n",
       " ['Impossible', 'nsubjpass', 'rated', 'VERB', [The, Mission]],\n",
       " ['was', 'auxpass', 'rated', 'VERB', []],\n",
       " ['rated', 'ROOT', 'rated', 'VERB', [Impossible, was, 7/10, by, .]],\n",
       " ['7/10', 'oprd', 'rated', 'VERB', []],\n",
       " ['by', 'agent', 'rated', 'VERB', [Tomatoes]],\n",
       " ['Rotten', 'compound', 'Tomatoes', 'PROPN', []],\n",
       " ['Tomatoes', 'pobj', 'by', 'ADP', [Rotten]],\n",
       " ['.', 'punct', 'rated', 'VERB', []]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dependency_tree_nodes('The Mission Impossible was rated 7/10 by Rotten Tomatoes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'det', 'Impossible', 'PROPN', []],\n",
       " ['Mission', 'compound', 'Impossible', 'PROPN', []],\n",
       " ['Impossible', 'nsubjpass', 'given', 'VERB', [The, Mission]],\n",
       " ['was', 'auxpass', 'given', 'VERB', []],\n",
       " ['given', 'ROOT', 'given', 'VERB', [Impossible, was, ratings, based, .]],\n",
       " ['7/10', 'nummod', 'ratings', 'NOUN', []],\n",
       " ['ratings', 'dobj', 'given', 'VERB', [7/10, by]],\n",
       " ['by', 'prep', 'ratings', 'NOUN', [Tomatoes]],\n",
       " ['Rotten', 'compound', 'Tomatoes', 'PROPN', []],\n",
       " ['Tomatoes', 'pobj', 'by', 'ADP', [Rotten]],\n",
       " ['based', 'prep', 'given', 'VERB', [on]],\n",
       " ['on', 'prep', 'based', 'VERB', [reviews]],\n",
       " ['273', 'nummod', 'reviews', 'NOUN', []],\n",
       " ['reviews', 'pobj', 'on', 'ADP', [273]],\n",
       " ['.', 'punct', 'given', 'VERB', []]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dependency_tree_nodes('The Mission Impossible was given 7/10 ratings by Rotten Tomatoes based on 273 reviews.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['7/10', 'nummod', 'ratings', 'NOUN', []],\n",
       " ['ratings', 'nsubjpass', 'given', 'VERB', [7/10]],\n",
       " ['was', 'auxpass', 'given', 'VERB', []],\n",
       " ['given', 'ROOT', 'given', 'VERB', [ratings, was, to, by, .]],\n",
       " ['to', 'dative', 'given', 'VERB', [Impossible]],\n",
       " ['Mission', 'compound', 'Impossible', 'ADJ', []],\n",
       " ['Impossible', 'pobj', 'to', 'ADP', [Mission]],\n",
       " ['by', 'agent', 'given', 'VERB', [Tomatoes]],\n",
       " ['Rotten', 'compound', 'Tomatoes', 'PROPN', []],\n",
       " ['Tomatoes', 'pobj', 'by', 'ADP', [Rotten]],\n",
       " ['.', 'punct', 'given', 'VERB', []]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dependency_tree_nodes('7/10 ratings was given to Mission Impossible by Rotten Tomatoes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rotten', 'compound', 'Tomatoes', 'NOUN', []],\n",
       " ['Tomatoes', 'nsubj', 'gave', 'VERB', [Rotten]],\n",
       " ['gave', 'ROOT', 'gave', 'VERB', [Tomatoes, ratings, to, based, .]],\n",
       " ['7/10', 'nummod', 'ratings', 'NOUN', []],\n",
       " ['ratings', 'dobj', 'gave', 'VERB', [7/10]],\n",
       " ['to', 'dative', 'gave', 'VERB', [Impossible]],\n",
       " ['the', 'det', 'Impossible', 'PROPN', []],\n",
       " ['Mission', 'compound', 'Impossible', 'PROPN', []],\n",
       " ['Impossible', 'pobj', 'to', 'ADP', [the, Mission]],\n",
       " ['based', 'prep', 'gave', 'VERB', [on]],\n",
       " ['on', 'prep', 'based', 'VERB', [reviews]],\n",
       " ['273', 'nummod', 'reviews', 'NOUN', []],\n",
       " ['users', 'compound', 'reviews', 'NOUN', []],\n",
       " ['reviews', 'pobj', 'on', 'ADP', [273, users]],\n",
       " ['.', 'punct', 'gave', 'VERB', []]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dependency_tree_nodes('Rotten Tomatoes gave 7/10 ratings to the Mission Impossible based on 273 users reviews.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/10 33 37 CARDINAL\n",
      "Rotten Tomatoes 41 56 PERSON\n",
      "273 66 69 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "doc = nlp (\"The Mission Impossible was rated 7/10 by Rotten Tomatoes based on 273 reviews of users.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
