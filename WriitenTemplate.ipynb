{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp('Mission Impossible was written by Chrisopher Nolan.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chrisopher Nolan 34 50 ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Mission Impossible was written by Chrisopher Nolan.')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching with wriiten template: for The film is directed by Aneesh Chaganty in his feature debut and written by Chaganty and Sev Ohanian\n",
      "Has valid verb:True\n",
      "vt:written\n",
      "token conj : written\n",
      "token.head: directed\n",
      "token nsubjpass : film\n",
      "extracted movie name is:The film\n",
      "verbTextChanged todirected\n",
      "vt:directed\n",
      "extracted writer name is:Aneesh Chaganty\n"
     ]
    }
   ],
   "source": [
    "#statement1 = 'The Mission Impossible was written by Chrisopher Nolan.'\n",
    "statement1 = 'The Searching is directed by Aneesh Chaganty in his feature debut and written by Chaganty and Sev Ohanian'\n",
    "#statement1 = 'herry film was written and produced by Joss Whedon and directed by jorge.'\n",
    "statement2 = 'Chrisopher Nolan wrote Mission Impossible.'\n",
    "isValidForWrittenTemplate = checkWrittenTemplateEligibility(statement1)\n",
    "if(isValidForWrittenTemplate):\n",
    "#     time = extractReleaseTime(statement)\n",
    "#     print(\"extracted time is:\"+str(time))\n",
    "    \n",
    "    movieName = extractMovieName(statement1)\n",
    "    print(\"extracted movie name is:\" + str(movieName))\n",
    "    \n",
    "    writerName = extractWriterName(statement1)\n",
    "    print(\"extracted writer name is:\" + str(writerName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractMovieName(statement):\n",
    "    targetVerbLemmas = ['write']\n",
    "    verbText = getTargetVerbAsAppearedInStatement(statement, targetVerbLemmas)\n",
    "    verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "    movieName = \"<uninitialized>\"\n",
    "    \n",
    "#     handle when release is with premiered.\n",
    "    '''\n",
    "    while verbTextDNode[1] == 'conj':\n",
    "        verbText = verbTextDNode[2]\n",
    "        print(\"verbTextChanged to : \"+verbText)\n",
    "        verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "    '''\n",
    "\n",
    "    print(\"vt:\"+verbText)\n",
    "\n",
    "    movieName = getMovie(statement,verbText)\n",
    "    \n",
    "    return movieName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractWriterName(statement):\n",
    "    targetVerbLemmas = ['write']\n",
    "    verbText = getTargetVerbAsAppearedInStatement(statement, targetVerbLemmas)\n",
    "    verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "    writerName = \"<uninitialized>\"\n",
    "    \n",
    "#     handle when release is with premiered.\n",
    "    while verbTextDNode[1] == 'conj':\n",
    "        verbText = verbTextDNode[2]\n",
    "        print(\"verbTextChanged to\"+verbText)\n",
    "        verbTextDNode = next(obj for obj in get_dependency_tree_nodes(statement) if obj[0] == verbText)\n",
    "\n",
    "    print(\"vt:\"+verbText)\n",
    "\n",
    "    writerName = getWriter(statement,verbText)\n",
    "    \n",
    "    return writerName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTargetVerbAsAppearedInStatement(statement, targetVerbLemmas):\n",
    "    \"\"\"\n",
    "    this will reutrn exact apperance of verb in statement.\n",
    "    ex: statement = \"Movie was written by James.\", targetVerbLemmas = ['write','script']\n",
    "    this will return \"written\" as it's lemma matches with one of the targetVerbLemmas\n",
    "    \"\"\"\n",
    "    verbTokens = filterVerbTokens(statement)\n",
    "    for token in verbTokens:\n",
    "        if token.lemma_ in targetVerbLemmas:\n",
    "            return token.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNounSubject(statement, verbText):\n",
    "    doc = nlp(statement)\n",
    "    for token in doc:\n",
    "        print(token.text, token.dep_, token.head.text)\n",
    "        if((token.dep_ == \"nsubjpass\" or token.dep_ == \"nsubj\") and token.head.text == verbText):\n",
    "            return token.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovie(statement, verbText):\n",
    "    doc = nlp(statement)\n",
    "    theme = \"<uninitialized>\" #movie\n",
    "    \n",
    "    for token in doc:\n",
    "        #print(token.text, token.dep_, token.head.text)        \n",
    "        if (token.dep_ == \"nsubjpass\" and token.head.text == verbText):\n",
    "            print(\"token nsubjpass : \" + token.text)\n",
    "            theme = getNounChunkThatContainsNoun(statement, token)\n",
    "            return theme\n",
    "        elif (token.dep_ == \"dobj\" and token.head.text == verbText):\n",
    "            theme = getNounChunkThatContainsNoun(statement, token)\n",
    "            return theme\n",
    "        elif ((token.dep_ == \"conj\" and token.head.text == verbText) or (token.dep_ == \"conj\" and token.text == verbText)):\n",
    "            print(\"token conj : \" + token.text)\n",
    "            if (token.head.dep_ == \"ROOT\"):\n",
    "                print(\"token.head: \" + token.head.text)\n",
    "                token1 = token.head\n",
    "                return getMovie(statement, token1.text)\n",
    "                '''\n",
    "                if (token.dep_ == \"nsubjpass\" and token.head.text == token1.text):\n",
    "                    theme = getNounChunkThatContainsNoun(statement, token)\n",
    "                    return theme\n",
    "                '''\n",
    "    \n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWriter(statement, verbText):\n",
    "    doc = nlp(statement)\n",
    "    agent = \"<uninitialized>\" #writer\n",
    "    '''\n",
    "    for token in doc:\n",
    "        #print(token.text, token.dep_, token.head.text)        \n",
    "        if (token.dep_ == \"agent\" and token.head.text == verbText):\n",
    "            token = [child for child in token.children][0]\n",
    "            agent = getNounChunkThatContainsNoun(statement, token)\n",
    "            return agent\n",
    "        elif (token.dep_ == \"nsubj\" and token.head.text == verbText):\n",
    "            agent = getNounChunkThatContainsNoun(statement, token)\n",
    "            return agent\n",
    "    '''\n",
    "    \n",
    "    for token in doc:\n",
    "        #print(\"token:\",token)\n",
    "        if (token.dep_ == \"agent\" and token.head.text == verbText):\n",
    "            token = [child for child in token.children][0]\n",
    "            agent = getNounChunkThatContainsNoun(statement, token)\n",
    "            return agent\n",
    "        elif (token.dep_ == \"nsubj\" and token.head.text == verbText):\n",
    "            agent = getNounChunkThatContainsNoun(statement, token)\n",
    "            return agent\n",
    "        \n",
    "        elif((token.dep_ == \"conj\" and token.head.text == verbText) or (token.dep_ == \"conj\" and token.text == verbText)):\n",
    "            #print(\"conj: \"+ token.text)\n",
    "            token1 = [child for child in token.children]\n",
    "            #print(token1[0], token1[1])\n",
    "            i = 0\n",
    "            while (i < len(token1)):\n",
    "                if (token1[i].dep_ == \"agent\"):\n",
    "                    token2 = [child1 for child1 in token1[i].children][0]\n",
    "                    #print(token2)\n",
    "                    agent = getNounChunkThatContainsNoun(statement, token2)\n",
    "                    return agent\n",
    "                i+=1\n",
    "        \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNounChunkThatContainsNoun(statement, nounSubject):\n",
    "    doc = nlp(statement)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if nounSubject.text in chunk.text:\n",
    "            return chunk.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkWrittenTemplateEligibility(statement):\n",
    "    print(\"Matching with wriiten template: for \" + statement)\n",
    "    hasValidVerb = check_verb_match(statement)\n",
    "    print(\"Has valid verb:\" + str(hasValidVerb))\n",
    "    \n",
    "    return hasValidVerb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_verb_match(statement):\n",
    "    verbTokens = filterVerbTokens(statement)\n",
    "    targetVerbs = ['write']\n",
    "    for token in verbTokens:\n",
    "        if token.lemma_ in targetVerbs:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterVerbTokens(statement):\n",
    "    doc = nlp(statement)\n",
    "    result = list(filter(lambda token: token.pos_ == \"VERB\" and token.lemma_ != \"be\", doc))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dependency_tree_nodes(sentence):\n",
    "    nodes = []\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        nodes.append([token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "          [child for child in token.children]])\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'det', 'Impossible', 'PROPN', []],\n",
       " ['Mission', 'compound', 'Impossible', 'PROPN', []],\n",
       " ['Impossible', 'nsubjpass', 'written', 'VERB', [The, Mission]],\n",
       " ['was', 'auxpass', 'written', 'VERB', []],\n",
       " ['written', 'ROOT', 'written', 'VERB', [Impossible, was, by, .]],\n",
       " ['by', 'agent', 'written', 'VERB', [Nolan]],\n",
       " ['Chrisopher', 'compound', 'Nolan', 'PROPN', []],\n",
       " ['Nolan', 'pobj', 'by', 'ADP', [Chrisopher]],\n",
       " ['.', 'punct', 'written', 'VERB', []]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dependency_tree_nodes('The Mission Impossible was written by Chrisopher Nolan.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Chrisopher', 'compound', 'Nolan', 'PROPN', []],\n",
       " ['Nolan', 'nsubj', 'wrote', 'VERB', [Chrisopher]],\n",
       " ['wrote', 'ROOT', 'wrote', 'VERB', [Nolan, Impossible, .]],\n",
       " ['Mission', 'compound', 'Impossible', 'PROPN', []],\n",
       " ['Impossible', 'dobj', 'wrote', 'VERB', [Mission]],\n",
       " ['.', 'punct', 'wrote', 'VERB', []]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dependency_tree_nodes('Chrisopher Nolan wrote Mission Impossible.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'det', 'Searching', 'PROPN', []],\n",
       " ['Searching', 'nsubjpass', 'directed', 'VERB', [The]],\n",
       " ['is', 'auxpass', 'directed', 'VERB', []],\n",
       " ['directed',\n",
       "  'ROOT',\n",
       "  'directed',\n",
       "  'VERB',\n",
       "  [Searching, is, by, in, and, written]],\n",
       " ['by', 'agent', 'directed', 'VERB', [Chaganty]],\n",
       " ['Aneesh', 'compound', 'Chaganty', 'PROPN', []],\n",
       " ['Chaganty', 'pobj', 'by', 'ADP', [Aneesh]],\n",
       " ['in', 'prep', 'directed', 'VERB', [debut]],\n",
       " ['his', 'poss', 'debut', 'NOUN', []],\n",
       " ['feature', 'compound', 'debut', 'NOUN', []],\n",
       " ['debut', 'pobj', 'in', 'ADP', [his, feature]],\n",
       " ['and', 'cc', 'directed', 'VERB', []],\n",
       " ['written', 'conj', 'directed', 'VERB', [by]],\n",
       " ['by', 'agent', 'written', 'VERB', [Chaganty]],\n",
       " ['Chaganty', 'pobj', 'by', 'ADP', [and, Sev, Ohanian]],\n",
       " ['and', 'cc', 'Chaganty', 'PROPN', []],\n",
       " ['Sev', 'conj', 'Chaganty', 'PROPN', []],\n",
       " ['Ohanian', 'conj', 'Chaganty', 'PROPN', []]]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dependency_tree_nodes('The Searching is directed by Aneesh Chaganty in his feature debut and written by Chaganty and Sev Ohanian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['herry', 'amod', 'film', 'NOUN', []],\n",
       " ['film', 'nsubjpass', 'written', 'VERB', [herry]],\n",
       " ['was', 'auxpass', 'written', 'VERB', []],\n",
       " ['written', 'ROOT', 'written', 'VERB', [film, was, and, directed]],\n",
       " ['and', 'cc', 'written', 'VERB', []],\n",
       " ['directed', 'conj', 'written', 'VERB', [by]],\n",
       " ['by', 'agent', 'directed', 'VERB', [Whedon]],\n",
       " ['Joss', 'compound', 'Whedon', 'PROPN', []],\n",
       " ['Whedon', 'pobj', 'by', 'ADP', [Joss]]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dependency_tree_nodes('herry film was written and directed by Joss Whedon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['herry', 'amod', 'film', 'NOUN', []],\n",
       " ['film', 'nsubjpass', 'written', 'VERB', [herry]],\n",
       " ['was', 'auxpass', 'written', 'VERB', []],\n",
       " ['written', 'ROOT', 'written', 'VERB', [film, was, and, produced, .]],\n",
       " ['and', 'cc', 'written', 'VERB', []],\n",
       " ['produced', 'conj', 'written', 'VERB', [by, and, directed]],\n",
       " ['by', 'agent', 'produced', 'VERB', [Whedon]],\n",
       " ['Joss', 'compound', 'Whedon', 'PROPN', []],\n",
       " ['Whedon', 'pobj', 'by', 'ADP', [Joss]],\n",
       " ['and', 'cc', 'produced', 'VERB', []],\n",
       " ['directed', 'conj', 'produced', 'VERB', [by]],\n",
       " ['by', 'agent', 'directed', 'VERB', [jorge]],\n",
       " ['jorge', 'pobj', 'by', 'ADP', []],\n",
       " ['.', 'punct', 'written', 'VERB', []]]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dependency_tree_nodes('herry film was written and produced by Joss Whedon and directed by jorge.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Searching' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-87712c67e5be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetNounChunkThatContainsNoun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Searching is directed by Aneesh Chaganty in his feature debut and written by Chaganty and Sev Ohanian'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSearching\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Searching' is not defined"
     ]
    }
   ],
   "source": [
    "getNounChunkThatContainsNoun('Searching is directed by Aneesh Chaganty in his feature debut and written by Chaganty and Sev Ohanian', Searching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dark Knight\n",
      "Aneesh Chaganty\n",
      "his feature debut\n",
      "Chaganty\n",
      "Sev\n",
      "Ohanian\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dark Knight is directed by Aneesh Chaganty in his feature debut and written by Chaganty and Sev Ohanian\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
