{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPOS(statement):\n",
    "    doc = nlp(statement)\n",
    "    print(\"\\n\\n-------------General info------\")\n",
    "    for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "              token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printEntities(statement):\n",
    "    doc = nlp(statement)\n",
    "    print(\"\\n\\n-------------Entities------\")\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isExpectedVerbToken(token):\n",
    "    return token.lemma_ in [\"release\",\"launch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterVerbTokens(statement):\n",
    "    doc = nlp(statement)\n",
    "    result = list(filter(lambda token: token.pos_ == \"VERB\" and token.lemma_ != \"be\", doc))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependency_tree_nodes(sentence):\n",
    "    nodes = []\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        nodes.append([token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "          [child for child in token.children]])\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDependencies(sentence):\n",
    "    nodes = get_dependency_tree_nodes(sentence)\n",
    "    print(\"\\n\\n------------- Deps ------\")\n",
    "    for node in nodes:\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNounChunks(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    print(\"\\n\\n------------- Noun chunks ------\")\n",
    "    for chunk in doc.noun_chunks:\n",
    "        print(chunk.text+ \" start:\"+str(chunk.start_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printEverything(sentence):\n",
    "    printPOS(sentence)\n",
    "    printEntities(sentence)\n",
    "    printNounChunks(sentence)\n",
    "    printDependencies(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------General info------\n",
      "As as ADP IN prep Xx True False\n",
      "of of ADP IN prep xx True True\n",
      "December december PROPN NNP pobj Xxxxx True False\n",
      "6 6 NUM CD nummod d False False\n",
      ", , PUNCT , punct , False False\n",
      "2018 2018 NUM CD nummod dddd False False\n",
      ", , PUNCT , punct , False False\n",
      "Ironman ironman PROPN NNP nsubj Xxxxx True False\n",
      "grossed gross VERB VBD ROOT xxxx True False\n",
      "$ $ SYM $ quantmod $ False False\n",
      "194.4 194.4 NUM CD compound ddd.d False False\n",
      "million million NUM CD dobj xxxx True False\n",
      "worldwide worldwide ADV RB advmod xxxx True False\n",
      "\n",
      "\n",
      "-------------Entities------\n",
      "December 6, 2018 6 22 DATE\n",
      "Ironman 24 31 ORG\n",
      "$194.4 million 40 54 MONEY\n",
      "\n",
      "\n",
      "------------- Noun chunks ------\n",
      "December start:6\n",
      "Ironman start:24\n",
      "\n",
      "\n",
      "------------- Deps ------\n",
      "['As', 'prep', 'grossed', 'VERB', [of]]\n",
      "['of', 'prep', 'As', 'ADP', [December]]\n",
      "['December', 'pobj', 'of', 'ADP', [6, ,, 2018]]\n",
      "['6', 'nummod', 'December', 'PROPN', []]\n",
      "[',', 'punct', 'December', 'PROPN', []]\n",
      "['2018', 'nummod', 'December', 'PROPN', []]\n",
      "[',', 'punct', 'grossed', 'VERB', []]\n",
      "['Ironman', 'nsubj', 'grossed', 'VERB', []]\n",
      "['grossed', 'ROOT', 'grossed', 'VERB', [As, ,, Ironman, million, worldwide]]\n",
      "['$', 'quantmod', 'million', 'NUM', []]\n",
      "['194.4', 'compound', 'million', 'NUM', []]\n",
      "['million', 'dobj', 'grossed', 'VERB', [$, 194.4]]\n",
      "['worldwide', 'advmod', 'grossed', 'VERB', []]\n"
     ]
    }
   ],
   "source": [
    "s1 = \"As of December 6, 2018, A Star Is Born has grossed $194.4 million worldwide, and $170.1 million in other territories, for a total worldwide gross of $364.5 million, against a production budget of $36â€“40 million.\"\n",
    "s1 = \"As of December 6, 2018, Ironman grossed $194.4 million worldwide\"\n",
    "sentence = s1\n",
    "printEverything(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depNodes(statement):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
