{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key nouns : Filming and Shooting\n",
    "# detect subject noun\n",
    "# get verb (scheduled, begun, ended) attached to the noun\n",
    "# location attached to that verb (token -> NER/Noun Phrase)\n",
    "# time attached to that verb (token -> NER/Noun Phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1 = \"Filming of Ironman at Edwards Air Force Base began in April 2, and ended on May 2.\"\n",
    "s2 = \"Shooting of Ironman began in April at Edwards Air Force Base and ended on May 2.\"\n",
    "s3 = \"Filming of Fallout was slated to start in Paris on April 10, 2017.\"\n",
    "s4 = \"Filming was scheduled to take place that month in the Northern Quarter of Manchester, where parts of the 2004 film Alfie and the 2009 Sherlock Holmes had been shot, followed by the Stanley Dock area of Liverpool, both doubling for the period's Lower East Side of Manhattan.\"\n",
    "# could not detect movie name as it is attached with the \"where\"\n",
    "s5 = \"On April 10, 2017, filming of Fallout was slated to start in Paris.\"\n",
    "s6 = \"Filming officially began on April 8.\"\n",
    "# Filming is detected as VERB in dependency tree\n",
    "s7 = \"Some of the filming also took place in New Zealand in July 2017.\"\n",
    "s8 = \"Filming concluded in the United Arab Emirates (UAE) on March 25, 2018.\"\n",
    "s9 = \"Filming began on March 12, 2007, with the first few weeks spent on Stark's captivity in Afghanistan.\"\n",
    "# scene detection failed due to connected with \"with\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Movie/Scene Filming ----\n",
      "Movie/Scene:<no-match>\n",
      "Location:Afghanistan\n",
      "Time:March 12, 2007\n"
     ]
    }
   ],
   "source": [
    "sent = s9\n",
    "parse(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(sent):\n",
    "    result = pattern1Match(sent)\n",
    "    printResult(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern1Match(sent):\n",
    "    \"\"\"\n",
    "    this should match pattern \"Filming of Ironman at Edwards Air Force Base began in mid-April, and ended on May 2.\"\n",
    "    it need Filming/Shooting \n",
    "    then it's verb (begun here) should have location or time\n",
    "    movie/scene can be attached as \"of\" with filming/shooting\n",
    "    \"\"\"\n",
    "    filmingToken = getFilmingNounToken(sent)\n",
    "    if(filmingToken == None):\n",
    "        return\n",
    "    else:\n",
    "        time = getTimeOfToken(sent, filmingToken.head)\n",
    "        location = getLocationOfToken(sent, filmingToken)\n",
    "        if(location == \"<no-match>\"):\n",
    "            location = getLocationOfToken(sent, filmingToken.head)\n",
    "        \n",
    "        #take if single exist\n",
    "        if location == \"<no-match>\":\n",
    "            \"\"\"this might open for wrong match but it could give better result at the end\"\"\"\n",
    "            location = getFirstGPE(sent)\n",
    "        if time == \"<no-match>\":\n",
    "            time = getFirstEntity(sent,[\"TIME\",\"DATE\"])\n",
    "        \n",
    "        if(location != \"<no-match>\" or time != \"<no-match>\"):\n",
    "            \"\"\"when atleast one of those matched.\"\"\"\n",
    "            movieName = getEntityRelatedByOF(sent,filmingToken)\n",
    "            return [movieName, location, time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilmingNounToken(sent):\n",
    "    \"\"\"\n",
    "    This will look for frequent noun of \"filming\" or \"shooting\"\n",
    "    \"\"\"\n",
    "    for token in nlp(sent):\n",
    "        if token.lemma_ in [\"filming\", \"shooting\"]:\n",
    "            return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResult(result):\n",
    "    print(\"---- Movie/Scene Filming ----\")\n",
    "    if(result != None):\n",
    "        print(\"Movie/Scene:\"+str(result[0]))\n",
    "        print(\"Location:\"+str(result[1]))\n",
    "        print(\"Time:\"+str(result[2]))\n",
    "    else:\n",
    "        print(\"No parse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeOfToken(sent, token):\n",
    "    for child in token.children: \n",
    "                #usually time starts with \"on\", \"in\", \"at\"\n",
    "                if child.text in [\"on\",\"at\",\"in\"]:\n",
    "                    #usually \"on\"'s child is [August] \n",
    "#                     print(\"checking children of \"+child.text)\n",
    "                    for subChild in child.children:\n",
    "                        temporalEntity = getTemporalThatContainsToken(sent, subChild)\n",
    "                        if(temporalEntity != None):\n",
    "                            return temporalEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemporalThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and ent.label_ == \"DATE\" and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def calculateStartPositionOfToken(statement, targetToken):\n",
    "    \"\"\"\n",
    "    this should return start position of the token\n",
    "    \"\"\"\n",
    "    matches = [m.start() for m in re.finditer(targetToken.text, statement)]\n",
    "    if(len(matches)==1):\n",
    "        return matches[0]\n",
    "    \n",
    "\n",
    "    huristicPosition = 0\n",
    "    doc = nlp(statement)\n",
    "    \n",
    "    i = 0\n",
    "    for token in doc:\n",
    "        if i < targetToken.i:\n",
    "            huristicPosition = huristicPosition + len(token.text)+1\n",
    "            i = i+1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    distances = []\n",
    "    for match in matches:\n",
    "        distances.append(abs(match-huristicPosition))\n",
    "        \n",
    "    minIndex = distances.index(min(distances))\n",
    "    \n",
    "    return matches[minIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocationOfToken(sent, token):\n",
    "    for child in token.children: \n",
    "        #usually release location starts with \"in\"\n",
    "        if child.text in [\"in\",\"throughout\", \"at\"]:\n",
    "            for subChild in child.children:\n",
    "#                 print(\"in loop for:\"+subChild.text)\n",
    "                GPEEntity = getLocationThatContainsToken(sent, subChild)\n",
    "                if GPEEntity == None:\n",
    "#                     print(\"no gpe found\")\n",
    "                    #this might be slipplary when \"at\" comes. Might confuse with time.\n",
    "                    canConfuseWithTime = (getTemporalThatContainsToken(sent, subChild) != None)\n",
    "#                     print(\"Can confuse:\"+subChild.text+\":\"+str(canConfuseWithTime))\n",
    "                    if not canConfuseWithTime:\n",
    "                        GPEEntity = getPhraseThatContainsToken(sent, subChild)\n",
    "                    \n",
    "                if GPEEntity != None:\n",
    "                    return GPEEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocationThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and ent.label_ != \"TIME\" and ent.label_ != \"DATE\"  and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhraseThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if(token.text in chunk.text and tokenStartPos >= chunk.start_char and tokenStartPos <= chunk.end_char):\n",
    "            return chunk.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityRelatedByOF(sent, token):\n",
    "    for child in token.children: \n",
    "                #usually movie name for noun attached with \"on\"\n",
    "                if child.text in [\"of\"]:\n",
    "                    #['of', 'prep', 'premiere', 'NOUN', [IronMan]]\n",
    "                    for subChild in child.children:\n",
    "                        entity = getEntityThatContainsToken(sent, subChild)\n",
    "                        if entity == None:\n",
    "                            entity = getPhraseThatContainsToken(sent, subChild)\n",
    "                        if(entity != None):\n",
    "                            return entity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstGPE(sent):\n",
    "    doc = nlp (sent)\n",
    "    for ent in doc.ents:\n",
    "        if(ent.label_ == \"GPE\"):\n",
    "            return ent.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstEntity(sent, expectedLabels):\n",
    "    doc = nlp (sent)\n",
    "    for ent in doc.ents:\n",
    "        if(ent.label_ in expectedLabels):\n",
    "            return ent.text\n",
    "    return \"<no-match>\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
