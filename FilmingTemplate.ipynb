{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"Filming of Ironman at Edwards Air Force Base began in April 2, and ended on May 2.\"\n",
    "s2 = \"Filming of Ironman began in April at Edwards Air Force Base and ended on May 2.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_filming_event(sent):\n",
    "    result = pattern1Match(sent)\n",
    "    \n",
    "    printResult(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern1Match(sent):\n",
    "    \"\"\"\n",
    "    this should match pattern \"Filming of Ironman at Edwards Air Force Base began in mid-April, and ended on May 2.\"\n",
    "    it need Filming/Shooting \n",
    "    then it's verb (begun here) should have location or time\n",
    "    movie/scene can be attached as \"of\" with filming/shooting\n",
    "    \"\"\"\n",
    "    filmingToken = getFilmingNounToken(sent)\n",
    "    if(filmingToken == None):\n",
    "        return\n",
    "    else:\n",
    "        time = getTimeOfToken(sent, filmingToken.head)\n",
    "        location = getLocationOfToken(sent, filmingToken)\n",
    "        if(location == \"<no-match>\"):\n",
    "#             print(\"No location match with filming\")\n",
    "            location = getLocationOfToken(sent, filmingToken.head)\n",
    "        if(location != \"<no-match>\" or time != \"<no-match>\"):\n",
    "            \"\"\"when atleast one of those matched.\"\"\"\n",
    "            movieName = getEntityRelatedByOF(sent,filmingToken)\n",
    "            return [movieName, location, time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in loop for:Base\n",
      "Movie/Scene:Ironman\n",
      "Location:Edwards Air Force Base\n",
      "Time:April 2\n"
     ]
    }
   ],
   "source": [
    "# pattern1Match(s2)\n",
    "# pattern1Match(\"Filming of Ironman began in April at Edwards Air Force Base and ended on May 2.\")\n",
    "\n",
    "match_filming_event(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilmingNounToken(sent):\n",
    "    \"\"\"\n",
    "    This will look for frequent noun of \"filming\" or \"shooting\"\n",
    "    \"\"\"\n",
    "    for token in nlp(sent):\n",
    "        if \"NOUN\" == token.pos_ and token.lemma_ in [\"filming\", \"shooting\"]:\n",
    "            return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResult(result):\n",
    "    if(result != None):\n",
    "        print(\"Movie/Scene:\"+str(result[0]))\n",
    "        print(\"Location:\"+str(result[1]))\n",
    "        print(\"Time:\"+str(result[2]))\n",
    "    else:\n",
    "        print(\"No Parse\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeOfToken(sent, token):\n",
    "    for child in token.children: \n",
    "                #usually time starts with \"on\", \"in\", \"at\"\n",
    "                if child.text in [\"on\",\"at\",\"in\"]:\n",
    "                    #usually \"on\"'s child is [August] \n",
    "#                     print(\"checking children of \"+child.text)\n",
    "                    for subChild in child.children:\n",
    "                        temporalEntity = getTemporalThatContainsToken(sent, subChild)\n",
    "                        if(temporalEntity != None):\n",
    "                            return temporalEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemporalThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and ent.label_ == \"DATE\" and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def calculateStartPositionOfToken(statement, targetToken):\n",
    "    \"\"\"\n",
    "    this should return start position of the token\n",
    "    \"\"\"\n",
    "    matches = [m.start() for m in re.finditer(targetToken.text, statement)]\n",
    "    if(len(matches)==1):\n",
    "        return matches[0]\n",
    "    \n",
    "\n",
    "    huristicPosition = 0\n",
    "    doc = nlp(statement)\n",
    "    \n",
    "    i = 0\n",
    "    for token in doc:\n",
    "        if i < targetToken.i:\n",
    "            huristicPosition = huristicPosition + len(token.text)+1\n",
    "            i = i+1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    distances = []\n",
    "    for match in matches:\n",
    "        distances.append(abs(match-huristicPosition))\n",
    "        \n",
    "    minIndex = distances.index(min(distances))\n",
    "    \n",
    "    return matches[minIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocationOfToken(sent, token):\n",
    "    for child in token.children: \n",
    "        #usually release location starts with \"in\"\n",
    "        if child.text in [\"in\",\"throughout\", \"at\"]:\n",
    "            for subChild in child.children:\n",
    "                print(\"in loop for:\"+subChild.text)\n",
    "                GPEEntity = getLocationThatContainsToken(sent, subChild)\n",
    "                if GPEEntity == None:\n",
    "#                     print(\"no gpe found\")\n",
    "                    #this might be slipplary when \"at\" comes. Might confuse with time.\n",
    "                    canConfuseWithTime = (getTemporalThatContainsToken(sent, subChild) != None)\n",
    "#                     print(\"Can confuse:\"+subChild.text+\":\"+str(canConfuseWithTime))\n",
    "                    if not canConfuseWithTime:\n",
    "                        GPEEntity = getPhraseThatContainsToken(sent, subChild)\n",
    "                    \n",
    "                if GPEEntity != None:\n",
    "                    return GPEEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocationThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and ent.label_ != \"TIME\" and ent.label_ != \"DATE\"  and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhraseThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if(token.text in chunk.text and tokenStartPos >= chunk.start_char and tokenStartPos <= chunk.end_char):\n",
    "            return chunk.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityRelatedByOF(sent, token):\n",
    "    for child in token.children: \n",
    "                #usually movie name for noun attached with \"on\"\n",
    "                if child.text in [\"of\"]:\n",
    "                    #['of', 'prep', 'premiere', 'NOUN', [IronMan]]\n",
    "                    for subChild in child.children:\n",
    "                        entity = getEntityThatContainsToken(sent, subChild)\n",
    "                        if entity == None:\n",
    "                            entity = getPhraseThatContainsToken(sent, subChild)\n",
    "                        if(entity != None):\n",
    "                            return entity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
