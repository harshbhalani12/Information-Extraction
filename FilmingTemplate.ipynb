{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"Filming of Ironman at Edwards Air Force Base began in April 2, and ended on May 2.\"\n",
    "s2 = \"Filming of Ironman began in April at Edwards Air Force Base and ended on May 2.\"\n",
    "s3 = \"Filming of Fallout was slated to start in Paris on April 10, 2017.\"\n",
    "s4 = \"Filming was scheduled to take place that month in the Northern Quarter of Manchester, where parts of the 2004 film Alfie and the 2009 Sherlock Holmes had been shot, followed by the Stanley Dock area of Liverpool, both doubling for the period's Lower East Side of Manhattan.\"\n",
    "s5 = \"On April 10, 2017, filming of Fallout was slated to start in Paris.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_filming_event(sent):\n",
    "    result = pattern1Match(sent)\n",
    "    \n",
    "    printResult(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern1Match(sent):\n",
    "    \"\"\"\n",
    "    this should match pattern \"Filming of Ironman at Edwards Air Force Base began in mid-April, and ended on May 2.\"\n",
    "    it need Filming/Shooting \n",
    "    then it's verb (begun here) should have location or time\n",
    "    movie/scene can be attached as \"of\" with filming/shooting\n",
    "    \"\"\"\n",
    "    filmingToken = getFilmingNounToken(sent)\n",
    "    if(filmingToken == None):\n",
    "        return\n",
    "    else:\n",
    "        time = getTimeOfToken(sent, filmingToken.head)\n",
    "        location = getLocationOfToken(sent, filmingToken)\n",
    "        if(location == \"<no-match>\"):\n",
    "            location = getLocationOfToken(sent, filmingToken.head)\n",
    "        \n",
    "        #take if single exist\n",
    "        if location == \"<no-match>\":\n",
    "            \"\"\"this might open for wrong match but it could give better result at the end\"\"\"\n",
    "            location = getFirstGPE(sent)\n",
    "        if time == \"<no-match>\":\n",
    "            time = getFirstEntity(sent,[\"TIME\",\"DATE\"])\n",
    "        \n",
    "        if(location != \"<no-match>\" or time != \"<no-match>\"):\n",
    "            \"\"\"when atleast one of those matched.\"\"\"\n",
    "            movieName = getEntityRelatedByOF(sent,filmingToken)\n",
    "            return [movieName, location, time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie/Scene:Fallout\n",
      "Location:Paris\n",
      "Time:April 10, 2017\n"
     ]
    }
   ],
   "source": [
    "# pattern1Match(s2)\n",
    "# pattern1Match(\"Filming of Ironman began in April at Edwards Air Force Base and ended on May 2.\")\n",
    "\n",
    "match_filming_event(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilmingNounToken(sent):\n",
    "    \"\"\"\n",
    "    This will look for frequent noun of \"filming\" or \"shooting\"\n",
    "    \"\"\"\n",
    "    for token in nlp(sent):\n",
    "        if \"NOUN\" == token.pos_ and token.lemma_ in [\"filming\", \"shooting\"]:\n",
    "            return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResult(result):\n",
    "    if(result != None):\n",
    "        print(\"Movie/Scene:\"+str(result[0]))\n",
    "        print(\"Location:\"+str(result[1]))\n",
    "        print(\"Time:\"+str(result[2]))\n",
    "    else:\n",
    "        print(\"No Parse\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeOfToken(sent, token):\n",
    "    for child in token.children: \n",
    "                #usually time starts with \"on\", \"in\", \"at\"\n",
    "                if child.text in [\"on\",\"at\",\"in\"]:\n",
    "                    #usually \"on\"'s child is [August] \n",
    "#                     print(\"checking children of \"+child.text)\n",
    "                    for subChild in child.children:\n",
    "                        temporalEntity = getTemporalThatContainsToken(sent, subChild)\n",
    "                        if(temporalEntity != None):\n",
    "                            return temporalEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemporalThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and ent.label_ == \"DATE\" and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def calculateStartPositionOfToken(statement, targetToken):\n",
    "    \"\"\"\n",
    "    this should return start position of the token\n",
    "    \"\"\"\n",
    "    matches = [m.start() for m in re.finditer(targetToken.text, statement)]\n",
    "    if(len(matches)==1):\n",
    "        return matches[0]\n",
    "    \n",
    "\n",
    "    huristicPosition = 0\n",
    "    doc = nlp(statement)\n",
    "    \n",
    "    i = 0\n",
    "    for token in doc:\n",
    "        if i < targetToken.i:\n",
    "            huristicPosition = huristicPosition + len(token.text)+1\n",
    "            i = i+1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    distances = []\n",
    "    for match in matches:\n",
    "        distances.append(abs(match-huristicPosition))\n",
    "        \n",
    "    minIndex = distances.index(min(distances))\n",
    "    \n",
    "    return matches[minIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocationOfToken(sent, token):\n",
    "    for child in token.children: \n",
    "        #usually release location starts with \"in\"\n",
    "        if child.text in [\"in\",\"throughout\", \"at\"]:\n",
    "            for subChild in child.children:\n",
    "#                 print(\"in loop for:\"+subChild.text)\n",
    "                GPEEntity = getLocationThatContainsToken(sent, subChild)\n",
    "                if GPEEntity == None:\n",
    "#                     print(\"no gpe found\")\n",
    "                    #this might be slipplary when \"at\" comes. Might confuse with time.\n",
    "                    canConfuseWithTime = (getTemporalThatContainsToken(sent, subChild) != None)\n",
    "#                     print(\"Can confuse:\"+subChild.text+\":\"+str(canConfuseWithTime))\n",
    "                    if not canConfuseWithTime:\n",
    "                        GPEEntity = getPhraseThatContainsToken(sent, subChild)\n",
    "                    \n",
    "                if GPEEntity != None:\n",
    "                    return GPEEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocationThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and ent.label_ != \"TIME\" and ent.label_ != \"DATE\"  and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhraseThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if(token.text in chunk.text and tokenStartPos >= chunk.start_char and tokenStartPos <= chunk.end_char):\n",
    "            return chunk.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityRelatedByOF(sent, token):\n",
    "    for child in token.children: \n",
    "                #usually movie name for noun attached with \"on\"\n",
    "                if child.text in [\"of\"]:\n",
    "                    #['of', 'prep', 'premiere', 'NOUN', [IronMan]]\n",
    "                    for subChild in child.children:\n",
    "                        entity = getEntityThatContainsToken(sent, subChild)\n",
    "                        if entity == None:\n",
    "                            entity = getPhraseThatContainsToken(sent, subChild)\n",
    "                        if(entity != None):\n",
    "                            return entity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstGPE(sent):\n",
    "    doc = nlp (sent)\n",
    "    for ent in doc.ents:\n",
    "        if(ent.label_ == \"GPE\"):\n",
    "            return ent.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstEntity(sent, expectedLabels):\n",
    "    doc = nlp (sent)\n",
    "    for ent in doc.ents:\n",
    "        if(ent.label_ in expectedLabels):\n",
    "            return ent.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
