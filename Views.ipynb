{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"The trailer was watched 224.6 million times in its first 24 hours, becoming the 2nd most viewed trailer in that time period.\"\n",
    "s2 = \"It was a big hit. Iron Man was watched 503.2 million times in first weekend.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Movie Views ----\n",
      "Movie:Iron Man\n",
      "View Count:503.2 million\n",
      "Time span:first weekend\n"
     ]
    }
   ],
   "source": [
    "sent = s2\n",
    "parse(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(sent):\n",
    "    result = pattern1Match(sent)\n",
    "    printResult(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern1Match(sent):\n",
    "    \"\"\"\n",
    "    this should match pattern \"As of December 6, 2018, A Star Is Born has grossed $194.4 million in the United States and Canada, and $170.1 million in other territories, for a total worldwide gross of $364.5 million, against a production budget of $36â€“40 million.\"\n",
    "    it need profit/earn/make/gross as verb \n",
    "    in addition money should exist in statement\n",
    "    movie/scene can be attached as subject of verb\n",
    "    \"\"\"\n",
    "    viewToken = getViewVerbToken(sent)\n",
    "    if(viewToken == None):\n",
    "        return\n",
    "    else:\n",
    "        movie = getThemeOfVerbToken(sent, viewToken)\n",
    "        viewCount = getFirstEntity(sent, [\"CARDINAL\"])\n",
    "        duration = getFirstEntity(sent, [\"TIME\",\"DATE\"])\n",
    "        return [movie, viewCount, duration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAgentOfVerbToken(sent, verbToken):\n",
    "    for child in verbToken.children:\n",
    "        if(child.dep_ == \"agent\"): #for \"by\"\n",
    "            for subChild in child.children:\n",
    "                return getPhraseThatContainsToken(sent, subChild)\n",
    "\n",
    "    for child in verbToken.children:\n",
    "        if(child.dep_ == \"pobj\" or child.dep_ == \"nsubj\"):\n",
    "            return getPhraseThatContainsToken(sent, child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThemeOfVerbToken(sent, verbToken):\n",
    "    for child in verbToken.children:\n",
    "        if(child.dep_ == \"dobj\" or child.dep_ == \"nsubjpass\"):\n",
    "            return getPhraseThatContainsToken(sent, child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getViewVerbToken(sent):\n",
    "    \"\"\"\n",
    "    This will look for frequent verb of \"view\", \"watch\"\n",
    "    Other synonyms can be used from wrodnet but we extracted a subset of synonys based on domain.\n",
    "    \"\"\"\n",
    "    for token in nlp(sent):\n",
    "        if \"VERB\" == token.pos_ and token.lemma_ in [\"view\", \"watch\"]:\n",
    "            return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSellVerbToken(sent):\n",
    "    \"\"\"\n",
    "    This will look for frequent verb of \"sell\"\n",
    "    Other synonyms can be used from wrodnet but we extracted a subset of synonys based on domain.\n",
    "    \"\"\"\n",
    "    for token in nlp(sent):\n",
    "        if \"VERB\" == token.pos_ and token.lemma_ in [\"sell\"]:\n",
    "            return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhraseOfFromChild(sent):\n",
    "    if \" from \" in sent:\n",
    "        for child in nlp(sent):\n",
    "            if child.text == \"from\":\n",
    "                for grandChild in child.children:\n",
    "                    return getPhraseThatContainsToken(sent, grandChild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhraseOfToChild(sent):\n",
    "    if \" to \" in sent:\n",
    "        for child in nlp(sent):\n",
    "            if child.text == \"to\":\n",
    "                for grandChild in child.children:\n",
    "                    return getPhraseThatContainsToken(sent, grandChild)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResult(result):\n",
    "    #[buyer, product, seller, amount, time, location]\n",
    "    print(\"---- Movie Views ----\")\n",
    "    if(result != None):\n",
    "        print(\"Movie:\"+str(result[0]))\n",
    "        print(\"View Count:\"+str(result[1]))\n",
    "        print(\"Time span:\"+str(result[2]))\n",
    "    else:\n",
    "        print(\"No Parse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeOfToken(sent, token):\n",
    "    for child in token.children: \n",
    "                #usually time starts with \"on\", \"in\", \"at\"\n",
    "                if child.text in [\"on\",\"at\",\"in\"]:\n",
    "                    #usually \"on\"'s child is [August] \n",
    "#                     print(\"checking children of \"+child.text)\n",
    "                    for subChild in child.children:\n",
    "                        temporalEntity = getTemporalThatContainsToken(sent, subChild)\n",
    "                        if(temporalEntity != None):\n",
    "                            return temporalEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemporalThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and ent.label_ == \"DATE\" and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def calculateStartPositionOfToken(statement, targetToken):\n",
    "    \"\"\"\n",
    "    this should return start position of the token\n",
    "    \"\"\"\n",
    "    matches = [m.start() for m in re.finditer(targetToken.text, statement)]\n",
    "    if(len(matches)==1):\n",
    "        return matches[0]\n",
    "    \n",
    "\n",
    "    huristicPosition = 0\n",
    "    doc = nlp(statement)\n",
    "    \n",
    "    i = 0\n",
    "    for token in doc:\n",
    "        if i < targetToken.i:\n",
    "            huristicPosition = huristicPosition + len(token.text)+1\n",
    "            i = i+1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    distances = []\n",
    "    for match in matches:\n",
    "        distances.append(abs(match-huristicPosition))\n",
    "        \n",
    "    minIndex = distances.index(min(distances))\n",
    "    \n",
    "    return matches[minIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocationOfToken(sent, token):\n",
    "    for child in token.children: \n",
    "        #usually release location starts with \"in\"\n",
    "        if child.text in [\"in\",\"throughout\", \"at\"]:\n",
    "            for subChild in child.children:\n",
    "#                 print(\"in loop for:\"+subChild.text)\n",
    "                GPEEntity = getLocationThatContainsToken(sent, subChild)\n",
    "                if GPEEntity == None:\n",
    "#                     print(\"no gpe found\")\n",
    "                    #this might be slipplary when \"at\" comes. Might confuse with time.\n",
    "                    canConfuseWithTime = (getTemporalThatContainsToken(sent, subChild) != None)\n",
    "#                     print(\"Can confuse:\"+subChild.text+\":\"+str(canConfuseWithTime))\n",
    "                    if not canConfuseWithTime:\n",
    "                        GPEEntity = getPhraseThatContainsToken(sent, subChild)\n",
    "                    \n",
    "                if GPEEntity != None:\n",
    "                    return GPEEntity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocationThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and ent.label_ != \"TIME\" and ent.label_ != \"DATE\"  and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhraseThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if(token.text in chunk.text and tokenStartPos >= chunk.start_char and tokenStartPos <= chunk.end_char):\n",
    "            return chunk.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityRelatedByOF(sent, token):\n",
    "    for child in token.children: \n",
    "                #usually movie name for noun attached with \"on\"\n",
    "                if child.text in [\"of\"]:\n",
    "                    #['of', 'prep', 'premiere', 'NOUN', [IronMan]]\n",
    "                    for subChild in child.children:\n",
    "                        entity = getEntityThatContainsToken(sent, subChild)\n",
    "                        if entity == None:\n",
    "                            entity = getPhraseThatContainsToken(sent, subChild)\n",
    "                        if(entity != None):\n",
    "                            return entity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstGPE(sent):\n",
    "    doc = nlp (sent)\n",
    "    for ent in doc.ents:\n",
    "        if(ent.label_ == \"GPE\"):\n",
    "            return ent.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstEntity(sent, expectedLabels):\n",
    "    doc = nlp(sent)\n",
    "    for ent in doc.ents:\n",
    "        if(ent.label_ in expectedLabels):\n",
    "            return ent.text\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findChildMoneyToken(sent, token):\n",
    "    for child in token.children:\n",
    "        if getMoneyThatContainsToken(sent, child) != None:\n",
    "            return child\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMoneyThatContainsToken(statement, token):\n",
    "    doc = nlp (statement)\n",
    "    tokenStartPos = calculateStartPositionOfToken(statement, token)\n",
    "    for ent in doc.ents:\n",
    "        if(token.text in ent.text and ent.label_ == \"MONEY\" and tokenStartPos >= ent.start_char and tokenStartPos <= ent.end_char):\n",
    "            return ent.text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doesTokenChildrenIncludeWorldWide(token):\n",
    "    for child in token.children:\n",
    "        if \"worldwide\" in child.text.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubjectTokenOfVerb(verbToken):\n",
    "    for child in verbToken.children:\n",
    "        if \"subj\" in child.dep_:\n",
    "            return child\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityRelatedByBy(sent, token):\n",
    "    for child in token.children: \n",
    "                if child.text in [\"by\"]:\n",
    "                    for subChild in child.children:\n",
    "                        entity = getEntityThatContainsToken(sent, subChild)\n",
    "                        if(entity != None):\n",
    "                            return entity\n",
    "    return \"<no-match>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
